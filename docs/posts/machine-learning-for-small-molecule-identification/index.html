


<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.81.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Machine Learning for Small Molecule Identification &middot; Yao Kai</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="https://fecodoo.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://fecodoo.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://fecodoo.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://fecodoo.github.io/css/hyde.css">
  

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Courier+Prime&family=Noto+Sans&family=Noto+Sans+SC&family=Ubuntu+Mono&family=ZCOOL+XiaoWei&display=swap" rel="stylesheet">



<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.ico">

  
  
</head>

  <body class="theme-base-08 ">
  <aside class="sidebar">
    <div class="container sidebar-sticky">
      <div class="sidebar-about">
        <a href="https://fecodoo.github.io/"><h1>Yao Kai</h1></a>
        <p class="lead">
         无不克则莫知其极，莫知其极，可以有国 
        </p>
      </div>
  
      <nav>
        <ul class="sidebar-nav">
          <li><a href="https://fecodoo.github.io/">Home</a> </li>
          <li><a href="https://github.com/fecodoo/"> Github </a></li><li><a href="https://www.linkedin.com/in/%e5%87%af-%e5%a7%9a-211242187"> LinkedIn </a></li><li><a href="https://t.me/fecodoo"> Telegram </a></li>
        </ul>
      </nav>
  
      <p class="copyright">&copy; 2021. All rights reserved. </p>
    </div>
  </aside>
  
    <main class="content container">
    <div class="post">
  <h1 class="post_title">Machine Learning for Small Molecule Identification</h1>
  <time datetime=2021-03-15T21:49:08&#43;0800 class="post-date">Mon, Mar 15, 2021</time>
  <h2 id="1-abstract">1 Abstract</h2>
<p>In metabolite anaysis, we are trying to study and annotate different molecules by thier features. However, small molecules typically contains similar structures and the space of potencial structures is tremendous (over 600 million). The amout of unique spectra covers only a small fraction of the entire database.</p>
<p>With the input out of the LC-MS^2 process, the machine learning algorithm runs like a search engine which assign ranked scores to predicted structures of high similarities. The point is to find suitable features. The output from <code>LC-MS</code> is flat feature vectors, and one common approach of is kernel methods which map embedded structured data into non-linear feature spaces.</p>
<h2 id="2-preprocessing">2 Preprocessing</h2>
<h3 id="21-lc-ms">2.1 LC-MS</h3>
<h4 id="211-liquid-chromatography">2.1.1 Liquid Chromatography</h4>
<p>Liquid Chromatography methods . It consists of 2 phases: mobile phase and stationary phase. LC can seperate molecules by their physicalchemical interactions with phases. Molecules that have stronger interactions with the staionary phase tend to ramain longer within the system, while those show weaker interactions spend less <code>retension time</code> inside the system.</p>
<p>This process seperate molecules from <code>time (physicalchemical interaction) dimension</code>.</p>
<h4 id="212-mass-spectrometry">2.1.2 Mass Spectrometry</h4>
<p>Mass Spectrometry diffirenciates molecules according to their mass. This process ionize the molecules and provide a seperation from <code>mass dimension</code>.</p>
<h4 id="213-lc-ms2-tandem-mass-spectrometry">2.1.3 LC-MS^2 (Tandem Mass Spectrometry)</h4>
<p>After a standard <code>LC-MS</code> workflow, we can add an additional MS process which break the target molecule into fragments, and then performs an analysis on the debris. It help us to understand the structure of the target molecule.</p>
<h2 id="3-kernel-methods">3 Kernel Methods</h2>
<p>Kernel methods are used to map features into higher dimensions for better seperation.</p>
<h3 id="31-non-linear-feature-map">3.1 Non-linear Feature Map</h3>
<p>If $κ$ is kernel, than there exists a function $\phi:X \rightarrow F_X$ (feature map) such that:</p>
<p>$$κ(x,x′) = \langle\phi(x),\phi(x′)\rangle F_X$$</p>
<p>In practice we don&rsquo;t have to get what $φ$ really is, this is called &ldquo;kernel trick&rdquo;. We can consider operation $κ$ as similarity measure between objects in $X$.</p>
<h3 id="32-kernelized-svm">3.2 Kernelized SVM</h3>
<p>A typical kernelized Support Vector Machine (SVM) for binary classification can be described as:</p>
<p>$$ h(x) = sign((\sum_{i=1}^{n}y_i\alpha_ik(x_i,x))+b) = sign(\langle w,\phi(x)\rangle + b) $$</p>
<ul>
<li>The training dataset is ${(x_i,y_i)}_{i=1}^{n}$</li>
<li>$\alpha_i \in R$ is the dual variables, $b \in R$ is the bias term</li>
<li>$κ(x_i,x)$ represents the similarity between training example $i$ and “new” example $x$</li>
<li>Kernel trick application: $w=\sum_i y_i\alpha_i \phi(x_i) \in F_X$</li>
</ul>
<h4 id="321-model-optimization-in-the-dual-space">3.2.1 Model Optimization in the Dual Space</h4>
<p>To search for the best $\alpha_i$, we need to:</p>
<p>$$\mathop{max}\limits_{\alpha} \sum_\limits{i=1}^{n}\alpha_i - \frac{1}{2}\sum_\limits{i=1}^{n}\sum_\limits{j=1}^{n} y_iy_j\alpha_i \alpha_j k(x_i,x_j) $$</p>
<p>$$s.t. 0\le \alpha_i \le C, \forall i \in {1,2,&hellip;,n};\sum_\limits{i=1}^{n}\alpha_iy_i=0$$</p>
<h2 id="4-csi-fingerid-to-prediction">4 CSI: FingerID to Prediction</h2>

</div>


    </main>

    
      
    
  </body>
</html>
